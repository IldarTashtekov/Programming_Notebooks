{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["htJrQDkf-fYv"],"authorship_tag":"ABX9TyP9RhJtYJ/xouuqgMrvgkDO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Setup"],"metadata":{"id":"_vebou1m9eqH"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","\n","import sys \n","import glob\n","import random\n","import os\n","import itertools \n","\n","from PIL import Image"],"metadata":{"id":"em1idsGRFXlL","executionInfo":{"status":"ok","timestamp":1673799204048,"user_tz":-60,"elapsed":4172,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#run after execute PathSetup in Google Drive part \n","from utils import ReplayBuffer"],"metadata":{"id":"eNXuQupmg2hE","executionInfo":{"status":"ok","timestamp":1673799319347,"user_tz":-60,"elapsed":1203,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["####Google Drive"],"metadata":{"id":"0PPklKD9-cgz"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZELWWLCX3TqB","executionInfo":{"status":"ok","timestamp":1673799230230,"user_tz":-60,"elapsed":17078,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}},"outputId":"66c7eba4-d510-44df-e4dd-a3911acd39c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","source":["Path setup"],"metadata":{"id":"b0YBhb3ZfcMS"}},{"cell_type":"code","source":["#!git clone https://github.com/JuanPabloMF/dl-pytorch\n","#!unzip /content/drive/MyDrive/Colab_Notebooks/Pytorch_Course/dl-pytorch/datasets/64x64_SIGNS.zip\n","\n","course_path = '/content/drive/MyDrive/Colab_Notebooks/Pytorch_Course/dl-pytorch/'\n","\n","sys.path.append(course_path)"],"metadata":{"id":"lq0U-xTofbeO","executionInfo":{"status":"ok","timestamp":1673799316032,"user_tz":-60,"elapsed":244,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["####Download Dataset"],"metadata":{"id":"htJrQDkf-fYv"}},{"cell_type":"code","source":["zip_path = '/content/drive/MyDrive/Colab_Notebooks/Pytorch_Course/PyTorch_GAN/archive.zip'\n","zip_output_path = '/content/drive/MyDrive/Colab_Notebooks/Pytorch_Course/PyTorch_GAN/Summer2Winter_yosemite/'"],"metadata":{"id":"MiV2pcxYDs2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","shutil.unpack_archive(zip_path, zip_output_path)"],"metadata":{"id":"LvZVUCD4Ds_y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ANN"],"metadata":{"id":"dUW5TUZVF9et"}},{"cell_type":"markdown","source":["####Dataset"],"metadata":{"id":"0jS_oRUAldJO"}},{"cell_type":"code","source":["class ImageDataset(Dataset):\n","  def __init__(self, base_dir, transform=None, split='train'):\n","    self.transform = transforms.Compose(transform)\n","                                                  #carpeta {split}/ carpeta A / todas las imagenes con formato        \n","    self.file_A = glob.glob(os.path.join(base_dir,'{}/A/*.*'.format(split)))\n","    self.file_B = glob.glob(os.path.join(base_dir,'{}/B/*.*'.format(split)))\n","\n","\n","  def __len__ (self):\n","    return max(len(self.files_A), len(self.files_B))    \n","\n","  def __getitem__(self,idx):\n","    image_A = self.transform(Image.open(self.filesA[idx])) #cargamos una imagen segun idx\n","    #como son colecciones no apariadas tomamos la imagen B no alineada con A con un random\n","    image_B = self.transform(Image.open(self.filesB[random.randint(0,len(self.file_B)-1)]))\n","    return {'A':image_A, 'B':image_B}\n","\n","\n"],"metadata":{"id":"xOmNeac3hnw2","executionInfo":{"status":"ok","timestamp":1673799324550,"user_tz":-60,"elapsed":186,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["####Models"],"metadata":{"id":"x7UDFLMblYq4"}},{"cell_type":"code","source":["class ResidualBlock(nn.Module):\n","  def __init__(self, in_features):\n","    super(ResidualBlock, self).__init__()\n","\n","    conv_block = [nn.ReflectionPad2d(1), #mejor padding\n","                  nn.Conv2d(in_features, in_features, 3),\n","                  nn.InstanceNorm2d(in_features), #Es BatchNorm para GANs\n","                  nn.ReLU(True),\n","                  nn.ReflectionPad2d(1), #mejor para conservar la distribucion de la imagen\n","                  nn.Conv2d(in_features,in_features,3),\n","                  nn.InstanceNorm2d(in_features)\n","                  ]\n","    self.con_block = nn.Sequential(*conv_block)\n","\n","  def forward(self, x):\n","    return self.conv_block(x) + x "],"metadata":{"id":"sa7okUBeGBoS","executionInfo":{"status":"ok","timestamp":1673799326515,"user_tz":-60,"elapsed":185,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class Generator(nn.Module):\n","  def __init__(self,input_nc,output_nc,n_residual_blocks=9):\n","    super(Generator,self).__init__()\n","\n","    #Bloque Convolucional\n","    model = [nn.ReflectionPad2d(3),\n","             nn.Conv2d(input_nc, 64, 7), #input chanels, 64 canales, filtro tamaño 7\n","             nn.InstanceNorm2d(64),\n","             nn.ReLU(True)\n","             ]\n","\n","    in_features = 64\n","    out_features = in_features * 2\n","\n","    #ENCODING\n","    #añadimos dos capas mas\n","    for _ in range(2):\n","                #capa de compreccion o encoding, divide x 2 el tamaño de la imagen de entrada I/2\n","      model += [nn.Conv2d(in_features,out_features,3,stride=2,padding=1), \n","                nn.InstanceNorm2d(out_features),\n","                nn.ReLU(True)\n","      ]   \n","\n","\n","      #inflamos x2 la cantidad de canales\n","      in_features = out_features #128\n","      out_features = in_features*2 #256\n","\n","      #Añadimos transformaciones residuales\n","      for _ in range(n_residual_blocks):\n","        model+=[ResidualBlock(in_features)]\n","\n","      #DECODING\n","      out_features = in_features //2  #//es una division de ints, / de floats, si usamos / data errores de tipo mas adelante\n","\n","      for _ in range(2):\n","                  #capa de deconvolucion multiplica x2 la imagen I·2\n","        model += [nn.ConvTranspose2d(in_features, out_features,3, stride=2, padding=1, output_padding=1),#deconvolucion\n","                  nn.InstanceNorm2d(out_features),\n","                  nn.ReLU(True)\n","                  ] \n","\n","        #antes aumentavamos la cantidad de canales, ahora los hacemos disminuir\n","        in_features = out_features\n","        out_features = in_features //2\n","\n","      #la capa de salida es una convolucion que va a aplanar todo\n","      model += [nn.ReflectionPad2d(3),\n","                nn.Conv2d(64, output_nc, 7), #I\n","                nn.Tanh()\n","                ]\n","                \n","      self.model = nn.Sequential(*model)\n","\n","\n","  #forward propagation\n","  def forward(self,x):\n","    return self.model(x)"],"metadata":{"id":"-d0fVCSyKKbL","executionInfo":{"status":"ok","timestamp":1673801081374,"user_tz":-60,"elapsed":277,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","  #PatchGAN: discrimina estilo o textura\n","  def __init__(self,input_nc):\n","    super(Discriminator,self).__init__()\n","\n","    model = [nn.Conv2d(input_nc, 64,4, stride=2, padding=1 ), #I/2\n","             nn.LeakyReLU(0.2, inplace=True),\n","             ]\n","\n","    model += [ nn.Conv2d(64, 128, 4, stride=2, padding=1), #I/2\n","              nn.InstanceNorm2d(128),\n","              nn.LeakyReLU(0.2, inplace=True)\n","              ]\n","\n","    model += [ nn.Conv2d(128, 256,4,stride=2, padding=1), #I/2\n","               nn.InstanceNorm2d(256),\n","               nn.LeakyReLU(0.2, inplace=True)\n","               ]\n","\n","    model += [ nn.Conv2d(256, 512,4,stride=2, padding=1), #I-1\n","               nn.InstanceNorm2d(512),\n","               nn.LeakyReLU(0.2, inplace=True)\n","               ] \n","\n","    #Flatten \n","    model += [ nn.Conv2d(512, 1, 4, padding=1)] #I-1\n","\n","\n","    self.model = nn.Sequential(*model)\n","\n","  def forward(self, x):\n","    x = self.model(x)\n","    return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0],-1)  #reducira el tamaño de la imagen a un solo valor la salida "],"metadata":{"id":"8LRGnhF4LVgb","executionInfo":{"status":"ok","timestamp":1673801089257,"user_tz":-60,"elapsed":168,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["####Instanciando redes, perdidas , optimizadores y perdidas"],"metadata":{"id":"0eQ6XuLtuMXW"}},{"cell_type":"code","source":["epochs = 0\n","n_epochs = 200\n","batch_size = 4\n","lr = 0.002\n","size = 256\n","input_nc = 3\n","output_nc = 3\n","decay_epoch = 100 \n","\n","cuda = True\n","device = torch.device('cuda' if cuda else 'cpu')\n","n_cpu = 8\n","\n","base_dir = '/content/drive/MyDrive/Colab_Notebooks/Pytorch_Course/PyTorch_GAN/Summer2Winter_yosemite/'\n"],"metadata":{"id":"EVYa7ukvuUNo","executionInfo":{"status":"ok","timestamp":1673801091972,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["#funcion que ayudara a inicializar los parametros de la red\n","def weights_init_normal(m):\n","  \n","  if isinstance(m, nn.Conv2d): #si la capa es de tipo convolucional\n","    torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n","  elif isinstance(m, nn.BatchNorm2d):\n","    torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n","    torch.nn.init.constant(m.bias, 0.0)"],"metadata":{"id":"wegyw7xYvKVu","executionInfo":{"status":"ok","timestamp":1673801093605,"user_tz":-60,"elapsed":221,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["#instanciamos las redes tanto generadoras como discriminadoras\n","netG_A2B = Generator(input_nc, output_nc)\n","netG_B2A = Generator(input_nc, output_nc)\n","netD_A = Discriminator(input_nc)\n","netD_B = Discriminator(input_nc)\n","\n","#aplicamos los pesos a las redes\n","netG_A2B.apply(weights_init_normal) \n","netG_B2A.apply(weights_init_normal) \n","netD_A.apply(weights_init_normal) \n","netD_B.apply(weights_init_normal)  \n","\n","#hacemos que las redes vayan en gpu si cuda es True\n","if cuda:\n","  netG_A2B.to(device)\n","  netG_B2A.to(device)\n","  netD_A.to(device)\n","  netD_B.to(device) \n","\n","#funciones de perdida\n","criterion_Gan = torch.nn.MSELoss() #mean squared error\n","criterion_cycle = torch.nn.L1Loss() #perdida L1, para ver la distancia entre las dos imagenes\n","criterion_identity = torch.nn.L1Loss #para comparar dos imagenes y ver si son similares"],"metadata":{"id":"Nt9Bb21JyYmA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673801095339,"user_tz":-60,"elapsed":475,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}},"outputId":"1d242827-9017-46f5-84f6-69900808939f"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-34-985c39b1e59f>:5: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","  torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n"]}]},{"cell_type":"markdown","source":["  Optimizadores y schedules"],"metadata":{"id":"eO1_FaDe1Tfx"}},{"cell_type":"code","source":["from torch.optim import lr_scheduler\n","#optimizadores\n","#las dor redes generadoras compartiran el mismo optimizador\n","optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n","                             lr=lr, betas=(0.5,0.999))\n","optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=lr, betas=(0.5,0.999))\n","optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=lr, betas=(0.5,0.999))\n","\n","#schedulers , actualizar el learning rate de forma dinamica durante el entrenamiento\n","\n","class LambdaLR():\n","  def __init__(self, n_epochs, offset, decay_start_epoch):\n","    assert ((n_epochs - decay_start_epoch) > 0)\n","    self.n_epochs = n_epochs\n","    self.offset = offset\n","    self.decay_start_epoch = decay_start_epoch\n","\n","  def step(self, epoch):\n","    return 1 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs- self.decay_start_epoch)\n","\n","\n","lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs,epochs,decay_epoch).step) #esta funcion dictara cada cuanto y como se actualizara el lr\n","lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs,epochs,decay_epoch).step) #esta funcion dictara cada cuanto y como se actualizara el lr\n","lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs,epochs,decay_epoch).step) #esta funcion dictara cada cuanto y como se actualizara el lr\n","\n"],"metadata":{"id":"5QTyvPiQ1Q1H","executionInfo":{"status":"ok","timestamp":1673801097585,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ildar Tashtekov","userId":"10535426126390802186"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["####Entrenar"],"metadata":{"id":"kvlTtpJd7syJ"}},{"cell_type":"code","source":["#inputs y targets\n","Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n","target_real = Tensor(batch_size).fill_(1.0)\n","target_fake = Tensor(batch_size).fill_(0.0)\n","\n","fake_a_buffer = ReplayBuffer()\n","fake_B_buffer = ReplayBuffer()\n","\n","#Dataloader\n","transform = [transforms.Resize(int(size*1.12), Image.BICUBIC),\n","             transforms.RandomCrop(size),\n","             transforms.RandomHorizontalFlip(),\n","             transforms.ToTensor(),\n","             transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n","             ]\n","\n","dataloader = DataLoader(ImageDataset(base_dir,transform=transform),\n","                       batch_size=batch_size, shuffle=True, num_workers=n_cpu, drop_last=True)\n","\n","#perdida de GAN\n","def Gen_GAN_loss(G,D,real,loss,target_real):\n","  #creo una imagen fake con red generativa\n","  fake = G(real)\n","  #hago una prediccion fake con red discriminativa\n","  pred_fake = D(fake)\n","  #la perdida\n","  L = loss(pred_fake,target_real)\n","  return L, fake\n","\n","#el cycle loss aplica las dos redes generativas y las compara con la imagen real\n","def cycle_loss(G1,G2,real,loss):\n","  recovered = G2(G1(real)) #recuperamos el ciclo g2 g1 de la iamgen real ?¿\n","  L = loss(recovered, real)\n","\n","#si la red modifica una imagen de A no queremos que modifique mucho la imagen \n","def identity_loss(G, real, loss):\n","  same = G(real)\n","  L = loss(same, real)\n","  return L"],"metadata":{"id":"EsCkZuOZ7Zoc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["loop de entrenamiento"],"metadata":{"id":"S0ygASluR0qN"}},{"cell_type":"code","source":["for epoch in range(epoch,n_epochs):\n","  for i, batch in enumerate(dataloader):\n","    real_A = batch['A'].to(device)\n","    real_B = batch['B'].to(device)\n","\n","    #Generativas\n","    optimizer_G.zero_grad()\n","    loss_GAN_A2B, fake_B = Gen_GAN_loss(netG_A2B, netD_B, real_A, criterion_GAN, target_real)\n","    loss_GAN_B2A, fake_A = Gen_GAN_loss(netG_B2A, netD_B, real_B, criterion_GAN, target_real)\n","\n","    loss_cycle_ABA = cycle_loss(netG_A2B, netG_B2A, real_A, criterion_cycle)\n","    loss_cycle_BAB = cycle_loss(netG_B2A, netG_A2B, real_B, criterion_cycle)\n","\n","    loss_identity_A = identity_loss(netG__B2A, real_A, criterion_identity)\n","    loss_identity_B = identity_loss(netG__A2B, real_B, criterion_identity)\n","\n","    loss_G = (loss_GAN_A2B + loss_GAN_B2A) + 10.0*(loss_cycle_ABA + loss_cycle_BAB) + 5.0 * (loss_identity_A + loss_identity_B)\n","    loss_G.backward()\n","\n","    optimizer_G.step\n","\n","    #Discriminativas\n","    optimizer_D_A.zero_grad()\n","    loss_D_A = Disc_GAN_loss(netD_A, fake_A, real_A, fake_A_buffer, criterion_GAN, target_real, target_fake)\n","    loss_D_A.backward()\n","    optimizer_D_A.step()\n","\n","    optimizer_D_B.zero_grad()\n","    loss_D_B = Disc_GAN_loss(netD_B, fake_B, real_B, fake_B_buffer, criterion_GAN, target_real, target_fake)\n","    loss_D_B.backward()\n","    optimizer_D_B.step()\n","\n","  lr_scheduler_G.step()\n","  lr_scheduler_D_A.step()\n","  lr_scheduler_D_B.step()"],"metadata":{"id":"GjGfKCxCR32n"},"execution_count":null,"outputs":[]}]}